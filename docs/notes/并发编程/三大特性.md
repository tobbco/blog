---
title: 并发编程三大特性
createTime: 2025/01/17 17:49:30
permalink: /concurrency/dkgzewc4/
tags:
  - 并发编程
  - 三大特性
---
## CPU层面

### 可见性

#### 缓存一致性问题的出现

在多核`CPU`系统中，每个`CPU`核心都拥有自己的私有缓存（`L1`和`L2`缓存），用于加速对内存的访问。此外，多个核心通常共享一个更大的缓存（`L3`缓存），它位于`L1`和`L2`缓存之后，容量更大，速度相对较慢。所有核心最终都访问`主内存`。**当多个核心同时访问和修改共享内存数据时，就会出现缓存一致性问题**。

**问题根源：**
由于每个核心拥有独立的缓存，当一个核心修改了共享内存中的数据，其修改后的数据首先只存在于该核心的缓存（`L1`或`L2`）中，而其他核心的缓存（`L1`、`L2`和`L3`）以及主内存中仍然保存着旧的数据。这导致不同核心对同一内存地址持有不同版本的数据，造成数据不一致。
**举例说明：**

#### CPU高速缓存模型

![image.png](https://raw.githubusercontent.com/tobbco/pics/main/20250121151955.png)
#### CPU缓存行(Cache Line)

CPU缓存并非以单个字节为单位存储数据，而是以更大的块为单位，这个块就叫做缓存行 (Cache Line) 或缓存块 (Cache Block)。 缓存行的大小通常是`64字节`（也有一些是32字节或128字节），这取决于具体的CPU架构。
当CPU需要访问内存中的某个数据时，它不会只读取单个字节，而是会将包含该数据所在的整个缓存行加载到缓存中。 这被称为缓存行填充 (Cache Line Fill)。 这样做是为了利用空间局部性原理：如果CPU访问了某个内存位置，它很可能很快会访问该位置附近的其他内存位置。通过一次性加载整个缓存行，可以减少后续访问内存的次数，从而提高性能。

比如`Java`中一个`Long`类型是`8`字节，一个缓存行最多就可以缓存`8`个`Long`类型数据。
#### MESI协议（缓存一致性）

并不是所有的CPU都基于MESI协议去制作CPU，但是主流的CPU大多都是基于MESI协议来**解决缓存一致性问题**的。

`MESI`协议是一种**缓存一致性协议**，用于在多核CPU系统中维护多个缓存之间的数据一致性。它是一种嗅探协议的变体，通过在每个缓存行中添加状态位来跟踪缓存行的数据状态，从而协调多个核心对共享数据的访问。 MESI协议中的四个状态分别代表：

- **M (Modified):** 该缓存行的数据被修改过，并且只有当前核心拥有该缓存行的副本。 主内存中的数据已经过期。
- **E (Exclusive):** 该缓存行的数据未被修改过，并且只有当前核心拥有该缓存行的副本。 主内存中的数据是有效的。
- **S (Shared):** 多个核心共享该缓存行的副本，数据未被修改过。 主内存中的数据是有效的。
- **I (Invalid):** 该缓存行的数据无效，不能被使用。

**MESI是如何保证缓存一致性的:**

**处于M状态的缓存行：**
- **行为:** 该缓存行的数据已被修改，且只有当前核心拥有该缓存行的副本。**主内存中的数据已过期**。
- **监听:** 该缓存行需要监听所有对该内存地址的读取请求（BusRd）。 在**其他核心尝试读取之前**，必须先将修改后的数据**写回主内存**（写回操作可能在读取操作之前或之后，取决于具体的实现），然后将**自身状态转换为S状态**。

**处于S状态的缓存行：**
- **行为:** 该缓存行的数据未被修改，且多个核心可能拥有该缓存行的副本。**主内存中的数据是有效的**。
- **监听:** 该缓存行需要监听对该内存地址的任何写入请求（BusRdX或BusUpgr）。 如果监听到写入请求，则需要将自身状态转换为`I`状态（失效）。

**处于E状态的缓存行：**
- **行为:** 该缓存行的数据未被修改，且只有当前核心拥有该缓存行的副本。**主内存中的数据是有效的**。
- **监听:** 该缓存行需要监听对该内存地址的读取请求（BusRd）。 如果监听到读取请求，则需要将自身状态转换为`S`状态（共享）。

#### CPU写优化层面对MESI协议的影响

**`CPU`的写优化技术**

`CPU`的写优化技术，例如写缓冲区（Store Buffer）和写合并缓冲区（Write Combining Buffer），会对`MESI`协议的运作产生一定的影响，主要体现在以下几个方面：

**1. 写缓冲区 (Store Buffer) 的影响：**
- **延迟可见性:** 写缓冲区允许CPU**将写操作的结果暂时存储在缓冲区中**，而**不立即写入缓存或主内存**。 这意味着其他核心可能无法立即看到由写缓冲区中的写操作所产生的结果。 **这与MESI协议的立即可见性（或至少是“合理时间内”可见性）目标相冲突**。 

**2. 写合并缓冲区 (Write Combining Buffer) 的影响：**
- **批量写入:** 写合并缓冲区可以将多个对同一缓存行的写操作合并成一个单一的写操作，从而减少内存访问次数。 这可以提高性能，但同时也增加了MESI协议的复杂性。 因为MESI协议需要跟踪每个缓存行的状态，而写合并缓冲区可能会延迟这些状态的更新。
- **一致性挑战:** 由于写合并缓冲区的存在，其他核心可能无法立即看到由写合并缓冲区中的写操作所产生的结果。 这与MESI协议的一致性要求相冲突。 为了解决这个问题，MESI协议的实现通常需要考虑写合并缓冲区的行为，并采取措施确保最终的一致性。

 **无效化队列 (Invalidate Queue)** 

无效化队列 (Invalidate Queue) 是多处理器系统中的一种硬件机制，用于优化缓存一致性协议（如MESI）的性能，特别是减少总线流量和延迟。 它主要用于处理缓存行的失效操作。

**传统方法的不足：**
在没有无效化队列的情况下，当一个处理器需要修改共享数据时，它需要向其他处理器广播失效信号（例如，在MESI协议中，写入操作会使其他处理器的缓存行失效）。 这个广播过程需要通过系统总线进行，如果系统中处理器数量很多，就会导致总线拥塞，降低性能。 此外，等待所有失效信号的确认也会增加延迟。

**无效化队列的工作原理：**
无效化队列是一个FIFO（先进先出）队列，用于存储待处理的缓存行失效请求。 当一个处理器需要修改共享数据时，它会将失效请求添加到自己的无效化队列中，而不是立即广播到总线上。 这个过程可以异步进行，不会阻塞处理器的执行。

当处理器空闲时，或者当达到一定的阈值时，处理器会批量处理无效化队列中的请求，并通过总线广播失效信号。 批量处理可以减少总线事务的次数，从而提高效率。 此外，一些实现可能允许在处理无效化队列时，将多个失效请求合并成一个请求，进一步减少总线流量。

**解决方案**

上述两种对`CPU`写操作的优化，会导致`MESI`协议触发存在延迟甚至无法触发的问题。在`CPU`层面为了解决这个问题，就需要一个指令，那就是`lock`指令。
**lock前缀指令** 期间的写操作，会立即写回主内存，那`CPU`的高速缓存必然也要写回去，必然会触发`MESI`协议，让其他缓存行将状态同步。
### 原子性

`CPU`原子性指的是`CPU`能够保证某些指令的执行是不可分割的，即在执行过程中不会被中断，但是程序的一个操作映射到`CPU`层面就可能是多个指令，例如`Java`中:`i++`:
- 首先从主内存读取`i`
- 寄存器计算+1
- 最后将`i`写回主内存
**原子指令的实现：**
`CPU`通过硬件机制来保证原子指令的原子性。 这些机制通常包括：
- **总线锁定:** 在执行原子指令期间`，CPU`会锁定总线，阻止其他处理器访问共享内存。 这是一种比较简单直接的方法，但效率较低，因为会阻塞其他处理器。
- **缓存锁定:** 在执行原子指令期间，`CPU`会锁定缓存行，阻止其他处理器访问该缓存行。 这比总线锁定效率更高，因为只阻塞访问同一缓存行的处理器。
- **特殊指令:** 一些`CPU`指令本身就是原子的，例如`xchg` (交换指令) 和 `cmpxchg` (比较并交换指令)。 这些指令的执行过程由`CPU`硬件保证原子性。

**Lock前缀指令** 在Intel官方的一些文档信息：[https://www.felixcloutier.com/x86/lock](https://www.felixcloutier.com/x86/lock)
### 有序性

CPU的有序性指的是CPU执行指令的顺序。 这分为两种情况：**程序顺序**和**执行顺序**。 它们之间存在差异，理解这种差异对于编写正确的多线程程序至关重要。
**1. 程序顺序 (Program Order):**
程序顺序是指指令在程序代码中出现的顺序。 这是程序员编写代码时所看到的指令顺序，也是程序员期望指令执行的顺序。 编译器和`CPU`都会尽力按照程序顺序执行指令，但并不总是能保证。
**2. 执行顺序 (Execution Order):**
执行顺序是指指令实际在`CPU`上执行的顺序。 由于`CPU`的各种优化技术，例如`指令重排序`、`流水线`、`缓存`等，执行顺序可能与程序顺序不同。 这些优化技术虽然可以提高`CPU`的性能，但也可能导致程序出现意想不到的结果，特别是`多线程程序`。

**CPU可能导致执行顺序与程序顺序不同的优化技术：**
- **指令重排序 (Instruction Reordering):** 编译器和`CPU`为了优化性能，可能会改变指令的执行顺序。 **只要不改变程序的最终结果，编译器和`CPU`就可以自由地重排序指令**。 这对于单线程程序通常没有问题，但对于多线程程序则可能导致数据竞争。
- **流水线 (Pipelining):** 现代`CPU`采用流水线技术，可以同时执行多条指令的不同阶段。 这使得指令的执行**并非严格按照程序顺序进行**。
- **缓存 (Cache):** `CPU`缓存可以加快内存访问速度，但缓存中的数据可能与主内存中的数据不一致。 这可能会导致指令的执行顺序与程序顺序不同。
- **多核处理器:** 在多核处理器中，多个核心同时执行指令，它们的执行顺序是相互独立的，这使得程序的执行顺序更加难以预测。
#### 有序性与多线程编程
在多线程编程中，CPU的有序性问题尤为重要。 如果多个线程共享同一个内存位置，并且它们的执行顺序与程序顺序不同，则可能导致`数据竞争`和程序错误。
#### 保证有序性的方法
为了保证程序的正确性，需要采取一些措施来保证指令的有序性：
- **内存屏障 (Memory Barrier):** 内存屏障，也称为内存栅栏 (Memory Fence)，是一种CPU指令，它强制`CPU`按照一定的顺序执行指令，阻止指令重排序。[https://gee.cs.oswego.edu/dl/jmm/cookbook.html](https://gee.cs.oswego.edu/dl/jmm/cookbook.html)
- **原子操作:** 原子操作是不可中断的，可以保证对共享内存的访问是原子的。 使用原子操作可以避免数据竞争，例如`CAS`操作
- **锁:** 锁可以保证在同一时间只有一个线程可以访问共享资源，从而避免数据竞争。

x86架构下三种主要的内存屏障指令：
- **`lfence` (Load Fence):** 加载屏障。 放在读指令之前，防止屏障前后的指令重排。
- **`sfence` (Store Fence):** 存储屏障。 放在写指令之前，防止屏障前后的指令重排。
- **`mfence` (Memory Fence):** 全能屏障。 同时具备`lfence`和`sfence`的功能。
## JMM层面
`Java`内存模型（Java Memory Model，`JMM`）是一个规范，它定义了Java虚拟机（`JVM`）中多线程程序如何访问共享内存。 它描述了线程和主内存之间以及线程工作内存之间交互的规则，目的是确保Java程序在多线程环境下的正确性和一致性。 理解JMM对于编写正确的并发程序至关重要。
### 关键概念
- **主内存 (Main Memory):** 所有线程共享的内存区域。 程序中的所有变量都存储在主内存中。
- **工作内存 (Working Memory):** 每个线程私有的内存区域。 线程在操作变量时，会先将变量从主内存复制到工作内存，操作完成后再将变量写回主内存。 工作内存中存储的是变量的副本，而不是变量本身。
- **共享变量 (Shared Variable):** 多个线程可以访问的变量。 共享变量存储在主内存中，每个线程在访问共享变量时，都需要先将变量复制到工作内存中
- **happens-before:** `JMM`使用`happens-before`原则来定义操作之间的顺序关系。 如果操作A happens-before 操作B，则保证操作A的结果对操作B可见，并且操作A的执行顺序在操作B之前。 happens-before原则并非直接定义执行顺序，而是定义可见性。 一些常见的happens-before关系包括：
    - **程序顺序规则:** 在一个线程内，按照程序代码的顺序执行的操作，前面的操作 happens-before 后面的操作。
    - **监视器锁规则:** 对一个锁的解锁操作 happens-before 对同一个锁的加锁操作。
    - **volatile变量规则:** 对一个 `volatile` 变量的写操作 happens-before 对同一个 `volatile` 变量的读操作。
    - **传递性:** 如果 A happens-before B，并且 B happens-before C，则 A happens-before C。
    - **线程启动规则:** 线程的启动操作 happens-before 线程的运行操作。
    - **线程终止规则:** 线程的运行操作 happens-before 线程的终止检测操作。
    - **中断规则:** 对线程的 `interrupt()` 方法的调用 happens-before 被中断线程检测到中断事件。
    - **终结规则:** 一个对象的构造函数的结束 happens-before 同一个对象 `finalize()` 方法的开始。
- **内存屏障 (Memory Barrier):** JMM通过内存屏障来保证操作的有序性。 内存屏障是一种特殊的指令，它可以阻止指令重排序，保证指令的执行顺序与程序顺序一致。 JVM会根据`happens-before`原则自动插入内存屏障。 开发者通常不需要直接操作内存屏障。
### JMM的作用
JMM的主要作用是规范线程对**共享变量的访问**，保证程序在多线程环境下的正确性。 它通过happens-before原则和内存屏障来实现以下目标：
- **保证共享变量的可见性:** 确保一个线程对共享变量的修改对其他线程可见。
- **保证共享变量的有序性:** 确保多个线程对共享变量的操作按照一定的顺序执行。
- **避免数据竞争:** 防止多个线程同时访问共享变量导致的数据不一致。
**与CPU缓存和内存一致性协议的关系:**
JMM与底层硬件的CPU缓存和内存一致性协议密切相关。 JMM的实现依赖于底层硬件的特性，但JMM提供了一个更高层次的抽象，屏蔽了底层硬件的细节，使开发者可以专注于程序逻辑，而无需关心底层硬件的具体实现。
### 原子性

### 可见性

### 有序性